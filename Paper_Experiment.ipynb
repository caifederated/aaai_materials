{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9bqOkYr6h2X",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Jli1LWc6h2h"
   },
   "source": [
    "# Import library & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "8vXkyTbk6h2i",
    "outputId": "dd883ea0-8cb1-48eb-deca-d45c2466376e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-9-d5bc9e1b63a9>:33} INFO - So this is shown on the console\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In jupyter notebook simple logging to console\n",
    "\"\"\"\n",
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "# To use differen't log level for file and console\n",
    "timestamp = datetime.datetime.utcnow().strftime('%Y%m%d_%H-%M-%S')\n",
    "filename=f'./log/tmp5a_{timestamp}.log'\n",
    "formatter = logging.Formatter('[%(asctime)s] %(name)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler(filename=filename)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "stream_handler = logging.StreamHandler(sys.stdout)\n",
    "stream_handler.setLevel(logging.INFO)\n",
    "\n",
    "# The handlers have to be at a root level since they are the final output\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG, \n",
    "    format='[{%(filename)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        file_handler,\n",
    "        stream_handler\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Test\n",
    "logger = logging.getLogger(\"simple_log\")\n",
    "logger.debug('This is hidden')\n",
    "logger.info('So this is shown on the console')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "XEGNV7u66h2n",
    "outputId": "3a062bb4-e1af-44c8-bd19-2f5d972996ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-10-f96dad092cfb>:17} INFO - [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import copy\n",
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import setup_clients\n",
    "\n",
    "from tqdm import trange\n",
    "from dataset import DATASET_ATTRIBUTES\n",
    "from client import Client\n",
    "from server import Server\n",
    "from utils_misc import get_all_L_next\n",
    "\n",
    "physical_devices = tf.config.experimental.get_visible_devices('GPU')\n",
    "logger.info(physical_devices)\n",
    "if len(physical_devices) > 0:\n",
    "    for i in range(len(physical_devices)):\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[i], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoDDjIty6h2t"
   },
   "source": [
    "# Load data and all associated parameter for our exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OydZ1nT26h2t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "DATASETS = ['mnist', 'femnist', 'celeba', 'cifar10']\n",
    "exp_dataset = DATASETS[2]\n",
    "\n",
    "mod = importlib.import_module(exp_dataset)\n",
    "ClientModel = getattr(mod, \"ClientModel\")\n",
    "\n",
    "attributes = DATASET_ATTRIBUTES[exp_dataset]\n",
    "SEED = 4151971\n",
    "input_shape = attributes['input_shape']\n",
    "dimension = attributes['dimension']\n",
    "'''\n",
    "move this out if you are using tf 2\n",
    " \n",
    "'''\n",
    "tf.random.set_seed(SEED) \n",
    "np.random.seed(SEED)\n",
    "\n",
    "eval_counter = 0\n",
    "def get_global_data(set_to_use='test'):\n",
    "    global eval_counter\n",
    "    num_stacking = round(len(clients) /4)  \n",
    "    id_start =  0 if eval_counter == 0 else num_stacking * eval_counter\n",
    "    id_end = num_stacking * (eval_counter + 1)\n",
    "    eval_counter += 1\n",
    "    if eval_counter >= 4:\n",
    "        eval_counter = 0 \n",
    "    stack_list = [c.id for c in clients[id_start: id_end]] \n",
    "         \n",
    "    for i in range(num_stacking):\n",
    "        if i == 0:\n",
    "            datax = test_data[stack_list[0]]['x']\n",
    "            datay = test_data[stack_list[0]]['y']\n",
    "        else:\n",
    "            x = test_data[stack_list[i]]['x']\n",
    "            datax = np.concatenate((datax, x), axis=0)\n",
    "            datay = np.concatenate((datay, test_data[stack_list[i]]['y']), axis=0)\n",
    "    \n",
    "    return {'x': datax, 'y': datay}\n",
    "\n",
    "def restore_set():\n",
    "    with open(\"./glob_testset_femnist\", \"rb\") as f:\n",
    "        datax, datay = pickle.load(f)\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((datax, datay))\n",
    "    global_data = dataset.batch(32)\n",
    "    \n",
    "    return global_data\n",
    "\n",
    "def restore_mnist_test():\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(test_data)\n",
    "    dataset = dataset.batch(32)\n",
    "    return dataset\n",
    "\n",
    "def get_history(d):\n",
    "    get_mean = lambda x: np.mean(x)\n",
    "    acc = [get_mean(i) for i in d['accuracy']]\n",
    "    return np.array(acc)\n",
    "    \n",
    "def get_loss(d):\n",
    "    get_mean = lambda x: np.mean(x)\n",
    "    lo = [get_mean(i) for i in d['loss']] \n",
    "    return np.array(lo)\n",
    "\n",
    "def cust_evaluate(batch_w):\n",
    "    first_key = [k for k in batch_w][0]\n",
    "    L_n = get_all_L_next(batch_w[first_key])\n",
    "    weight = server.batch_weights[0]\n",
    "    nn = current_model.create_CNNmodel(L_n)\n",
    "    nn.build(ins_c_model.get_input_shape)\n",
    "    nn.set_weights(weight)\n",
    "    history = nn.evaluate(test_set, verbose=1)\n",
    "    \n",
    "def IMCK(server, local_epochs=10, sem=False, bbp_map=False):\n",
    "    tf.keras.backend.clear_session()\n",
    "    server.select_clients(clients, num_worker_per_round)\n",
    "    if sem:\n",
    "        server.init_sem_data(dimension)\n",
    "        print(\"before sem running, data x looks like {}\".format(np.array(server._sem_dataset).shape ))\n",
    "    clients2key, key2clients, avg_w = server.train_model(local_epochs)\n",
    "    server.update_weights(avg_w, key2clients, clients2key)\n",
    "    server.evaluate_global_models(test_set)    \n",
    "    for key in key2clients:\n",
    "        logger.info(\"cluster_{} assigned {} clients\".format(key, len(key2clients[key])))    \n",
    "    return clients2key, key2clients, avg_w    \n",
    "\n",
    "\n",
    "def IMCK_MA(server, local_epochs=10, sem=False):\n",
    "    tf.keras.backend.clear_session()\n",
    "    server.select_clients(clients, num_worker_per_round)\n",
    "    if sem:\n",
    "        server.init_sem_data(dimension)    \n",
    "    clients2key, key2clients = server.train_model_with_ma(local_epochs)\n",
    "    for key in key2clients:\n",
    "        logger.info(\"cluster_{} assigned {} clients\".format(key, len(key2clients[key])))       \n",
    "\n",
    "iterations = 10\n",
    "num_workers = len(clients)\n",
    "num_worker_per_round = 15\n",
    "num_clusters = 1\n",
    "local_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = setup_clients\n",
    "_setup_func = getattr(mod, 'setup_clients_{}'.format(exp_dataset))\n",
    "\n",
    "lr = attributes['lr']\n",
    "avg_batch_size = 10\n",
    "\n",
    "op = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9, decay=1e-6)\n",
    "current_model = ClientModel(SEED, lr, train_bs=avg_batch_size, optimizer = op, input_shape=input_shape)\n",
    "if exp_dataset in ['femnist', 'celeba']:\n",
    "    clients, train_data, test_data = _setup_func(current_model)\n",
    "    test_set = current_model.create_dataset(get_global_data(), 'test') \n",
    "else:\n",
    "    clients, train_data, test_data = _setup_func(100, current_model)\n",
    "    test_set = restore_mnist_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD5li5FG6h23"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2-7-bvW6h24"
   },
   "source": [
    "# fedavg (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxftTIJP6h2-"
   },
   "source": [
    "# fedsgd (epoch 1, batch all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3EyJHdL6h3C"
   },
   "source": [
    "# feddist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RG4URHaP6h3H"
   },
   "source": [
    "# fedsem (cluster = 2, sem=True, no bbp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dKSCs7rk6h3H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{<ipython-input-6-c7f740eadbfb>:4} INFO - ==============================\n",
      "[{<ipython-input-6-c7f740eadbfb>:5} INFO - Start training on <celeba>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "before sem running, data x looks like (5, 2306)\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5068\n",
      "cluster  0 test accuracy 0.51\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4932\n",
      "cluster  1 test accuracy 0.49\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_0 assigned 2 clients\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_1 assigned 3 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [01:31<04:35, 91.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "before sem running, data x looks like (5, 2306)\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4932\n",
      "cluster  0 test accuracy 0.49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4932\n",
      "cluster  1 test accuracy 0.49\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_0 assigned 5 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [02:35<02:46, 83.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "before sem running, data x looks like (5, 2306)\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6931 - accuracy: 0.4932\n",
      "cluster  0 test accuracy 0.49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4932\n",
      "cluster  1 test accuracy 0.49\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_0 assigned 3 clients\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_1 assigned 2 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [02:57<01:04, 64.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "[{server.py:73} INFO - using gaus init to set client sem vectors and dimensions 1152, vec shape (2306,)\n",
      "before sem running, data x looks like (5, 2306)\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.4932\n",
      "cluster  0 test accuracy 0.49\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.6933 - accuracy: 0.4932\n",
      "cluster  1 test accuracy 0.49\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_0 assigned 3 clients\n",
      "[{<ipython-input-4-2f8fd22cff75>:83} INFO - cluster_1 assigned 2 clients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:43<00:00, 55.90s/it]\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 6\n",
    "local_epochs = 4\n",
    "current_model.SGD = False\n",
    "logging.info(\"==\"*15)\n",
    "logger.info(\"Start training on <{}>\".format(exp_dataset))\n",
    "server = Server(current_model, num_clusters = num_clusters)\n",
    "\n",
    "for t in trange(iterations):\n",
    "    clients2key, key2clients, avg_w = IMCK(server, local_epochs, sem=True)\n",
    "    server.firstCommunicationRound = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zckFRJk26h3L"
   },
   "source": [
    "# fedsem (cluster = 2, sem=True and used bbp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_misc import get_flatten_vec, get_all_L_next\n",
    "\n",
    "# d = get_flatten_vec(server.shared_nn.get_weights(), server.fc_idx)\n",
    "# print(d.shape)\n",
    "# print(get_all_L_next(server.shared_nn.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tfSsqKX26h3M",
    "outputId": "ed40f54d-0910-4a7c-edfa-9f0dc2633da7"
   },
   "outputs": [],
   "source": [
    "# current_model.SGD = False\n",
    "# current_model.optimizer.learning_rate = lr\n",
    "\n",
    "\n",
    "# logging.info(\"==\"*15)\n",
    "# logger.info(\"Start training on <{}>\".format(exp_dataset))\n",
    "\n",
    "# server = Server(current_model, num_clusters = num_clusters)\n",
    "# server.firstCommunicationRound = True\n",
    "# for t in trange(iterations):\n",
    "#     IMCK_MA(server, local_epochs, sem=True)\n",
    "#     server.evaluate_global_models_with_ma(test_set)\n",
    "#     server.firstCommunicationRound = False\n",
    "\n",
    "# for _ in range(4):\n",
    "#     ts_data = current_model.create_dataset(get_global_data(), 'test')\n",
    "#     eval_model(server.c_model, ts_data)\n",
    "\n",
    "\n",
    "# logger.info(\"Finished section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ld5tEkuvApV2"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data):  \n",
    "    loss, acc = model.evaluate(data, verbose=1)\n",
    "    print(\"loss {}, acc {}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hoauQOfC6h3Q"
   },
   "source": [
    "# hypcluster (cluster = 2, assign cluster label by model loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "UKOW6WxJ7Oh7"
   },
   "outputs": [],
   "source": [
    "#@title Parameter config\n",
    "#@markdown Forms support many types of fields.\n",
    "\n",
    "iterations = 44 #@param\n",
    "num_clusters = 2 #@param\n",
    "local_epochs = 20 #@param\n",
    "num_worker_per_round = 45 #@param\n",
    "lr = 0.006\n",
    "#@markdown ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ymNXrEi26h3Q",
    "outputId": "7d01bb0e-527a-44b8-cd0c-05fda99e01e1"
   },
   "outputs": [],
   "source": [
    "# current_model.SGD = False\n",
    "# current_model.optimizer.learning_rate = lr\n",
    "\n",
    "\n",
    "# logging.info(\"==\"*15)\n",
    "# logger.info(\"Start training on <{}>\".format(exp_dataset))\n",
    "\n",
    "# server = Server(current_model, num_clusters = num_clusters)\n",
    "# server.firstCommunicationRound = True\n",
    "# for t in trange(iterations):\n",
    "#     clients2key, key2clients, avg_w = IMCK(server, local_epochs)\n",
    "#     server.firstCommunicationRound = False\n",
    "\n",
    "# for _ in range(4):\n",
    "#     ts_data = current_model.create_dataset(get_global_data(), 'test')\n",
    "#     eval_model(server.c_model, ts_data)\n",
    "\n",
    "\n",
    "# logger.info(\"Finished section\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Df1qR3O6h3V"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ra4ud_pU6h3V",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(get_history(server.history))\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(get_loss(server.history))\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oumaGnn96h3Z"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Plot all baselines to a bar chart\n",
    "'''\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "labels = ['MNIST', 'FEMNIST']\n",
    "men_means = [20, 34]\n",
    "women_means = [25, 32]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, men_means, width, label='Men')\n",
    "rects2 = ax.bar(x + width/2, women_means, width, label='Women')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by group and gender')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4e1Y3xQ6h3c"
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"./glob_testset_femnist\", \"wb+\") as f:\n",
    "#     glob_x, glob_y = get_global_data()\n",
    "#     pickle.dump((glob_x, glob_y), f)\n",
    "\n",
    "\n",
    "# model = celeba_model.create_model()\n",
    "# ds = celeba_model.create_dataset(clients[0].train_data)\n",
    "# history = model.fit(ds, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All under this heading are code for colab vm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/content/drive/My Drive/fed_data')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ICFA_mnist.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
